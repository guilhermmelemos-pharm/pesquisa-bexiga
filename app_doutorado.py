import streamlit as st
import pandas as pd
from Bio import Entrez
import time
import plotly.express as px

# ==========================================
# 1. CONFIGURA√á√ÉO INICIAL DA P√ÅGINA
# ==========================================
st.set_page_config(
    page_title="Lemos Buscador", 
    page_icon="üß¨", 
    layout="wide"
)

st.title("üß¨ Lemos Buscador")
st.markdown("""
**Ferramenta de Intelig√™ncia Bibliom√©trica**
1. Insira seu e-mail (obrigat√≥rio).
2. O sistema far√° a varredura e gerar√° um **Relat√≥rio de Intelig√™ncia** autom√°tico.
3. No final, use o **Raio-X** para ver os artigos reais.
""")

# ==========================================
# 2. BARRA LATERAL (INPUTS)
# ==========================================
st.sidebar.header("‚öôÔ∏è Par√¢metros de Pesquisa")

email_user = st.sidebar.text_input("Seu E-mail (Obrigat√≥rio):", 
                                  value="", placeholder="ex: pesquisador@unifesp.br")

# LISTA MESTRA (Mantivemos a mesma lista completa)
lista_sugestao = """
-- AUTOFAGIA --
Autophagy, LC3B (MAP1LC3B), Beclin-1 (BECN1), p62 (SQSTM1), 
ATG5, ATG7, ULK1, LAMP2, TFEB, AMPK, mTOR,

-- FATORES DE CRESCIMENTO & FIBROSE --
VEGF, VEGFR1, VEGFR2, NRP1 (Neuropilin), VEGF-B,
TGF-beta1, CTGF, Galectin-3, MMP-9, NGF, BDNF,

-- CANAIS I√îNICOS & RECEPTORES --
P2X3, P2X7, TRPV1, TRPV4, BK channel, Kv7.4, SK3, 
Piezo1, Piezo2, Beta-3 Adrenergic, Muscarinic M3,
Cannabinoid CB1, Cannabinoid CB2,

-- ENZIMAS, INFLAMA√á√ÉO & OUTROS --
SGLT2, PDE5, ROCK (Rho-kinase), ACE2, Angiotensin II,
COX-2, NLRP3, IL-17, TLR4, Nrf2, PPAR-gamma
"""

lista_limpa = lista_sugestao.replace("\n", " ").replace("-- AUTOFAGIA --", "").replace("-- FATORES DE CRESCIMENTO & FIBROSE --", "").replace("-- CANAIS I√îNICOS & RECEPTORES --", "").replace("-- ENZIMAS, INFLAMA√á√ÉO & OUTROS --", "")
lista_limpa = " ".join(lista_limpa.split())

alvos_input = st.sidebar.text_area("Lista de Alvos:", value=lista_limpa, height=300)

st.sidebar.markdown("---")
st.sidebar.info("Buscas em INGL√äS com operadores booleanos.")

termo_fonte = st.sidebar.text_input("Termos Fonte (Modelos):", 
                                    value="Kidney OR Renal OR Blood Vessels OR Vascular OR Lung OR Airway OR Intestine OR Gut OR Diabetic Nephropathy")

termo_alvo = st.sidebar.text_input("Termos Alvo (Bexiga):", 
                                   value="Bladder OR Vesical OR Urothelium OR Detrusor OR Cystitis OR Painful Bladder OR Overactive Bladder")

botao_buscar = st.sidebar.button("üöÄ Iniciar Lemos Buscador", type="primary")

# ==========================================
# 3. FUN√á√ïES (PUBMED E AN√ÅLISE)
# ==========================================
def consultar_pubmed_count(termo_farmaco, termo_orgao, email):
    Entrez.email = email
    termo_farmaco = termo_farmaco.replace(",", "").strip()
    query = f"({termo_farmaco}) AND ({termo_orgao})"
    try:
        handle = Entrez.esearch(db="pubmed", term=query, retmax=0)
        record = Entrez.read(handle)
        return int(record["Count"])
    except:
        return -1

def buscar_resumos_bexiga(termo_farmaco, termo_orgao, email, max_results=5):
    Entrez.email = email
    termo_farmaco = termo_farmaco.replace(",", "").strip()
    query = f"({termo_farmaco}) AND ({termo_orgao})"
    
    try:
        handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results, sort="relevance")
        record = Entrez.read(handle)
        id_list = record["IdList"]
        
        if not id_list: return []
            
        handle = Entrez.efetch(db="pubmed", id=id_list, rettype="medline", retmode="text")
        records = handle.read()
        
        artigos = []
        raw_articles = records.split("\n\n")
        
        for art in raw_articles:
            lines = art.split("\n")
            title = "Sem T√≠tulo"
            source = "Fonte desconhecida"
            pmid = "N/A"
            for line in lines:
                if line.startswith("TI  - "): title = line[6:]
                if line.startswith("TA  - "): source = line[6:]
                if line.startswith("PMID- "): pmid = line[6:]
            if pmid != "N/A":
                artigos.append({"PMID": pmid, "T√≠tulo": title, "Revista": source})
        return artigos
    except Exception as e:
        return [{"Erro": str(e)}]

def gerar_analise_textual(df):
    """ Gera um resumo inteligente baseado nos dados """
    top_nicho = df.iloc[0]
    total_nichos = len(df[df['Potencial'] > 10])
    
    texto = f"""
    ### üß† An√°lise Autom√°tica
    O algoritmo varreu **{len(df)} alvos farmacol√≥gicos**.
    
    **1. O Grande Destaque:**
    A maior oportunidade detectada foi para **{top_nicho['Alvo']}**. 
    Este alvo √© **{top_nicho['Potencial']} vezes mais estudado** nos modelos comparativos (Rim/Vaso/Pulm√£o) do que na Bexiga.
    Isso indica uma maturidade cient√≠fica alta em outras √°reas, mas um terreno quase virgem no seu campo.
    
    **2. Volume de Oportunidades:**
    Encontramos **{total_nichos} alvos classificados como 'Nichos de Ouro'** (Ratio > 10x). 
    Esses s√£o os candidatos ideais para reposicionamento imediato.
    
    **3. Sugest√£o de Pr√≥ximo Passo:**
    Recomendamos focar a leitura nos resumos de **{top_nicho['Alvo']}** (usando a ferramenta abaixo) para verificar se os poucos artigos existentes ({top_nicho['Bexiga Total']}) j√° cobriram o mecanismo que voc√™ deseja propor.
    """
    return texto

# ==========================================
# 4. L√ìGICA PRINCIPAL
# ==========================================
if botao_buscar:
    # --- BLOQUEIO DE E-MAIL ---
    if not email_user or "@" not in email_user or len(email_user) < 5:
        st.error("‚õî PARE! O preenchimento do E-mail √© obrigat√≥rio para acessar o PubMed.")
        st.stop() # Para a execu√ß√£o aqui se n√£o tiver e-mail
    
    else:
        alvos_lista = [x.strip() for x in alvos_input.split(",") if x.strip()]
        resultados = []
        progresso = st.progress(0)
        total = len(alvos_lista)
        
        for i, alvo in enumerate(alvos_lista):
            n_fonte = consultar_pubmed_count(alvo, termo_fonte, email_user)
            n_bexiga = consultar_pubmed_count(alvo, termo_alvo, email_user)
            
            if n_fonte != -1:
                ratio = n_fonte / n_bexiga if n_bexiga > 0 else n_fonte
                resultados.append({
                    "Alvo": alvo,
                    "Fonte Total": n_fonte,
                    "Bexiga Total": n_bexiga,
                    "Potencial": round(ratio, 1)
                })
            progresso.progress((i + 1) / total)
            time.sleep(0.1)

        st.session_state['dados'] = pd.DataFrame(resultados).sort_values(by="Potencial", ascending=False)
        st.success("Varredura conclu√≠da!")

# --- PARTE 2: EXIBI√á√ÉO ---
if 'dados' in st.session_state:
    df = st.session_state['dados']
    
    # 1. RESUMO DE INTELIG√äNCIA (NOVIDADE)
    st.divider()
    with st.container():
        st.markdown("## üìù Resumo de Intelig√™ncia")
        st.info(gerar_analise_textual(df))
    
    st.divider()

    # 2. Gr√°fico e Tabela
    col_chart, col_table = st.columns([1, 1])
    
    with col_chart:
        st.subheader("üìä Ranking de Oportunidade")
        fig = px.bar(df.head(15), x="Alvo", y="Potencial", color="Potencial", 
                     title="Top 15 Nichos (Ratio Fonte/Bexiga)", color_continuous_scale="Bluered")
        st.plotly_chart(fig, use_container_width=True)
        
    with col_table:
        st.subheader("üìã Dados Brutos")
        st.dataframe(df.style.background_gradient(subset=['Potencial'], cmap="Greens").hide(axis="index"), 
                     use_container_width=True, height=400)

    st.divider()

    # 3. RAIO-X
    st.header("üîé Raio-X do Nicho: Valida√ß√£o")
    st.markdown("Selecione um alvo para ler os resumos:")
    
    lista_alvos = df['Alvo'].tolist()
    alvo_selecionado = st.selectbox("Alvo:", lista_alvos)
    
    if st.button(f"Buscar Artigos sobre {alvo_selecionado}"):
        with st.spinner(f"Lemos Buscador investigando {alvo_selecionado}..."):
            artigos = buscar_resumos_bexiga(alvo_selecionado, termo_alvo, email_user)
            
            if not artigos:
                st.balloons()
                st.success(f"üíé CONFIRMADO! Zero artigos encontrados para '{alvo_selecionado}' na bexiga.")
            else:
                st.warning(f"Aten√ß√£o: J√° existem {len(artigos)} artigos principais. Verifique se n√£o saturaram o tema.")
                for art in artigos:
                    with st.expander(f"üìÑ {art.get('T√≠tulo', 'Sem T√≠tulo')}"):
                        st.write(f"**Revista:** {art.get('Revista', 'N/A')}")
                        st.markdown(f"[Ler no PubMed](https://pubmed.ncbi.nlm.nih.gov/{art.get('PMID', '')})")
